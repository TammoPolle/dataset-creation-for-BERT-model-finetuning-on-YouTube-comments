{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-13T06:32:44.757674Z",
     "start_time": "2024-06-13T06:29:31.278919Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "source_path = \"E:\\\\research\\\\experiments\\\\n-p\\\\n-gram baseline\\\\min_len\\\\bert-base_745_all\\\\\"\n",
    "number_of_labels = 745\n",
    "\n",
    "# Laden der NLTK-Daten (einmalig erforderlich)\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Funktion zur Tokenisierung\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text.lower())\n",
    "\n",
    "# Einlesen der Kommentare und Labels aus einer CSV-Datei mit Tabulator-Trennzeichen\n",
    "def load_data(file_path):\n",
    "    comments = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) == 2:\n",
    "                comments.append(row[0])\n",
    "                labels.append(int(row[1]))\n",
    "    return comments, labels\n",
    "\n",
    "# Einlesen der Test-Kommentare aus einer CSV-Datei mit Tabulator-Trennzeichen\n",
    "def load_test_comments(file_path):\n",
    "    ids = []\n",
    "    comments = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) >= 2:\n",
    "                ids.append(row[0])\n",
    "                comments.append(row[1])\n",
    "    return ids, comments\n",
    "\n",
    "# Speichern der Kommentare und ihrer Vorhersagen in einer CSV-Datei mit Tabulator-Trennzeichen\n",
    "def save_predictions(ids, comments, predictions, output_file_path):\n",
    "    with open(output_file_path, 'w', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        for id, comment, prediction in zip(ids, comments, predictions):\n",
    "            writer.writerow([id, comment, prediction])\n",
    "\n",
    "# Erstellen und Trainieren des N-Gram-Modells\n",
    "def train_ngram_model(comments, labels, n=2):\n",
    "    vectorizer = CountVectorizer(tokenizer=tokenize, ngram_range=(1, n))\n",
    "    X = vectorizer.fit_transform(comments)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)\n",
    "    loss = log_loss(y_test, y_pred_prob)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Validation Log Loss: {loss}')\n",
    "    print(f'Validation Accuracy: {accuracy}')\n",
    "    return model, vectorizer\n",
    "\n",
    "# Klassifizierung eines neuen Kommentars\n",
    "def classify_comments(comments, model, vectorizer):\n",
    "    X_new = vectorizer.transform(comments)\n",
    "    predictions = model.predict(X_new)\n",
    "    return predictions\n",
    "\n",
    "# Hauptfunktion\n",
    "if __name__ == \"__main__\":\n",
    "    # Beispiel f체r das Einlesen der Trainingsdaten (채ndern Sie den Pfad entsprechend)\n",
    "    comments, labels = load_data(source_path + \"training_set.csv\")\n",
    "    \n",
    "    # Training des Modells\n",
    "    n = 5  # Beispiel f체r ein Bigramm-Modell\n",
    "    model, vectorizer = train_ngram_model(comments, labels, n)\n",
    "\n",
    "    # Einlesen der Test-Kommentare (채ndern Sie den Pfad entsprechend)\n",
    "    ids, test_comments = load_test_comments(source_path + 'testing_set.csv')\n",
    "    \n",
    "    # Klassifizieren der Test-Kommentare\n",
    "    predictions = classify_comments(test_comments, model, vectorizer)\n",
    "    \n",
    "    # Speichern der Ergebnisse in einer Ausgabedatei\n",
    "    save_predictions(ids, test_comments, predictions, source_path + 'n5\\\\prediction.tsv')\n",
    "\n",
    "    print('Predictions saved to predicted_labels.csv')"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T06:32:44.759702Z",
     "start_time": "2024-06-13T06:32:44.759702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trainingdata_preparation import tdp\n",
    "with open(source_path + \"n5\\\\comparative_data.txt\", 'a', encoding='utf-8') as cf:\n",
    "    cf.write(\"==== Experiment: {}-gram-baseliner ====\\n\".format(n))\n",
    "    cf.write(tdp.evaluation(source_path + 'testing_val_set.csv', source_path + \"n5\\\\prediction.tsv\", number_of_labels))"
   ],
   "id": "e7732bc99de1bbf9",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
